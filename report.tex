\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[vietnamese]{babel}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{geometry}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{float}
\usepackage{float}
\usepackage{multirow}
\usepackage{parskip}
\setlength{\parskip}{0.5em}
\geometry{margin=2.5cm}

% Code listing style
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    showstringspaces=false
}

\begin{document}

% Title page
\begin{titlepage}
    \centering
    \vspace*{1cm}
    
    {\Large\bfseries ĐẠI HỌC BÁCH KHOA HÀ NỘI}\\[0.3cm]
    {\large TRƯỜNG CÔNG NGHỆ THÔNG TIN \& TRUYỀN THÔNG}\\[2cm]
    
    \rule{\textwidth}{1pt}\\[0.5cm]
    {\LARGE\bfseries BÁO CÁO HỌC PHẦN}\\[0.3cm]
    {\Large TÍNH TOÁN HIỆU NĂNG CAO (IT5408)}\\[0.5cm]
    \rule{\textwidth}{1pt}\\[1.5cm]
    
    {\Large\bfseries Đề tài:}\\[0.3cm]
    {\large Ứng dụng tính toán song song và phân tán trong mô hình học sâu}\\[0.3cm]
    {\large (So sánh C++ và Python với MPI)}\\[2cm]
    
    \begin{tabular}{ll}
        \textbf{Nhóm thực hiện:} &  \\[0.5cm]
        \textbf{Giảng viên hướng dẫn:} & Vũ Văn Thiệu \\[0.5cm]
        \textbf{Bộ môn:} & Tính toán hiệu năng cao \\
    \end{tabular}
    
    \vfill
    {\large Hà Nội, 2026}
\end{titlepage}

% Table of contents
\tableofcontents
\newpage

%==============================================================================
\section{Đặt vấn đề}
%==============================================================================

\subsection{Bối cảnh và động lực nghiên cứu}

Trong thập kỷ vừa qua, học sâu (Deep Learning) đã chứng minh được sức mạnh vượt trội trong nhiều lĩnh vực như nhận dạng hình ảnh, xử lý ngôn ngữ tự nhiên, và hệ thống đề xuất. Tuy nhiên, sự thành công này đi kèm với một thách thức lớn về mặt tính toán: các mô hình ngày càng phức tạp với hàng trăm triệu thậm chí hàng tỷ tham số, và được huấn luyện trên các bộ dữ liệu khổng lồ. Việc huấn luyện tuần tự trên một CPU đơn lẻ trở nên bất khả thi, có thể kéo dài hàng tuần hoặc hàng tháng.

Tính toán song song và phân tán (Parallel and Distributed Computing) nổi lên như một giải pháp tất yếu. Bằng cách phân phối khối lượng tính toán khổng lồ lên nhiều đơn vị xử lý (CPU cores, GPU, hoặc các máy tính khác nhau trong một cụm), thời gian huấn luyện có thể được rút ngắn đáng kể, từ vài tuần xuống còn vài giờ hoặc vài ngày, thúc đẩy quá trình nghiên cứu và phát triển mô hình.

Nghiên cứu này tập trung vào việc áp dụng một trong những mô hình tính toán song song phổ biến nhất - \textbf{Song song hóa theo dữ liệu (Data Parallelism)} - vào bài toán huấn luyện mạng nơ-ron cơ bản, sử dụng giao tiếp truyền thông điệp (Message Passing Interface - MPI) để quản lý và đồng bộ các tiến trình tính toán.

\subsection{Mô tả bài toán cụ thể}

Bài toán được lựa chọn để minh họa là bài toán phân loại chữ số viết tay kinh điển trên tập dữ liệu MNIST. Mục tiêu là xây dựng và so sánh hiệu năng của hai phiên bản thuật toán:
\begin{enumerate}
    \item \textbf{Phiên bản tuần tự (Sequential):} Thực hiện toàn bộ quá trình lan truyền tiến (forward propagation) và lan truyền ngược (backpropagation) trên một tiến trình duy nhất.
    \item \textbf{Phiên bản song song (Parallel):} Phân chia dữ liệu huấn luyện cho nhiều tiến trình. Mỗi tiến trình tính toán gradient cục bộ (local gradient) trên một phần dữ liệu của mình, sau đó đồng bộ và tổng hợp lại để cập nhật mô hình chung.
\end{enumerate}

\textbf{Yếu tố then chốt} của nghiên cứu không chỉ dừng lại ở việc đạt được tốc độ tính toán nhanh hơn, mà còn ở việc đảm bảo tính \textbf{đúng đắn} (correctness) của thuật toán song song so với phiên bản gốc tuần tự, thể hiện qua độ chính xác (accuracy) cuối cùng của mô hình.

\subsection{Dữ liệu, Đầu vào và Đầu ra}

\subsubsection{Tập dữ liệu MNIST}
MNIST (Modified National Institute of Standards and Technology database) là tập dữ liệu kinh điển bao gồm 70,000 ảnh xám của chữ số viết tay (0-9), trong đó 60,000 ảnh cho huấn luyện và 10,000 ảnh cho kiểm tra. Trong nghiên cứu này, để phù hợp với mục đích minh họa và thời gian chạy thử nghiệm, chúng tôi sử dụng một tập con:
\begin{itemize}
    \item \textbf{Tập huấn luyện (Training set):} 4000 mẫu.
    \item \textbf{Tập kiểm tra (Test set):} 1000 mẫu.
    \item \textbf{Kích thước ảnh:} Được giảm xuống còn 20x20 pixel (400 features) từ kích thước gốc 28x28 để giảm độ phức tạp tính toán.
    \item \textbf{Tiền xử lý:} Giá trị pixel được chuẩn hóa về khoảng [0, 1] bằng cách chia cho 255.
\end{itemize}

\subsubsection{Biểu diễn dữ liệu}
\begin{itemize}
    \item \textbf{Đầu vào (Input - X):} Một ma trận có kích thước \texttt{(m x 400)}, với \texttt{m} là số lượng mẫu trong một batch (hoặc toàn bộ tập dữ liệu). Mỗi hàng đại diện cho một ảnh đã được "làm phẳng" (flattened).
    \item \textbf{Đầu ra thực tế (Ground Truth - y):} Một vector nhãn có kích thước \texttt{(m,)} với giá trị nguyên từ 0 đến 9.
    \item \textbf{Đầu ra dự đoán (Prediction - \hat{y}):} Một ma trận có kích thước \texttt{(m x 10)}. Mỗi hàng là một vector xác suất (probability distribution) trên 10 lớp, thu được qua hàm kích hoạt Sigmoid tại lớp đầu ra. Trong quá trình huấn luyện, nhãn thực tế \texttt{y} được chuyển thành định dạng \textbf{one-hot encoding} có cùng kích thước \texttt{(m x 10)} để tính toán hàm mất mát.
\end{itemize}

%==============================================================================
\section{Cơ sở lý thuyết và Thuật toán}
%==============================================================================

\subsection{Tổng quan về Mạng Nơ-ron Truyền thẳng (Feedforward Neural Network)}

Mạng nơ-ron truyền thẳng, hay Multilayer Perceptron (MLP), là kiến trúc cơ bản nhất trong học sâu. Nó bao gồm nhiều lớp (layers) nơ-ron kết nối đầy đủ (fully connected). Thông tin chỉ di chuyển một chiều từ lớp đầu vào, qua các lớp ẩn, đến lớp đầu ra, không có vòng phản hồi.

Mô hình trong nghiên cứu này có cấu trúc 3 lớp:
\begin{itemize}
    \item \textbf{Lớp đầu vào (Input Layer - $L_1$):} 400 nơ-ron, tương ứng với 400 pixel của ảnh đầu vào. \textit{Lưu ý:} Trong tính toán, chúng ta thêm một nơ-ron bias (luôn bằng 1) vào mỗi lớp, nên thực tế số lượng tham số tại lớp này là 401.
    \item \textbf{Lớp ẩn (Hidden Layer - $L_2$):} 25 nơ-ron. Đây là lớp trung gian học các đặc trưng (features) trừu tượng từ dữ liệu thô. Hàm kích hoạt Sigmoid được sử dụng.
    \item \textbf{Lớp đầu ra (Output Layer - $L_3$):} 10 nơ-ron, tương ứng với 10 chữ số cần phân loại. Hàm kích hoạt Sigmoid cũng được sử dụng để đầu ra có thể được diễn giải như xác suất (dù softmax thường phổ biến hơn cho bài toán phân loại nhiều lớp).
\end{itemize}

\subsection{Hàm kích hoạt Sigmoid}

Hàm Sigmoid (hay Logistic function) ánh xạ một giá trị thực bất kỳ ($z$) về một giá trị nằm trong khoảng (0, 1), rất phù hợp cho việc mô hình hóa xác suất.
\begin{equation}
    \sigma(z) = \frac{1}{1 + e^{-z}}
    \label{eq:sigmoid}
\end{equation}

Đạo hàm của hàm Sigmoid có dạng đơn giản và dễ tính toán, một ưu điểm lớn cho thuật toán lan truyền ngược:
\begin{equation}
    \sigma'(z) = \sigma(z) \cdot (1 - \sigma(z))
    \label{eq:sigmoid_derivative}
\end{equation}

\subsection{Khởi tạo trọng số}

Việc khởi tạo trọng số ($\theta$) một cách thông minh là rất quan trọng để tránh hiện tượng gradient biến mất (vanishing gradient) hoặc bùng nổ (exploding gradient), đặc biệt trong mạng sâu. Chúng tôi sử dụng phương pháp khởi tạo \textbf{Xavier/Glorot}, được đề xuất bởi Glorot và Bengio (2010). Các trọng số được lấy mẫu ngẫu nhiên từ một phân phối đều (uniform distribution):
\begin{equation}
    \theta \sim \mathcal{U}\left( -\sqrt{\frac{6}{n_{in} + n_{out}}}, \ +\sqrt{\frac{6}{n_{in} + n_{out}}} \right)
    \label{eq:xavier_init}
\end{equation}
Trong đó, $n_{in}$ và $n_{out}$ lần lượt là số lượng nơ-ron đầu vào và đầu ra của lớp chứa trọng số $\theta$. Phương pháp này giúp giữ phương sai (variance) của tín hiệu đầu ra ổn định khi nó truyền qua mạng.

\subsection{Quá trình Lan truyền tiến (Forward Propagation)}

Đây là quá trình tính toán đầu ra của mạng ($h$) từ đầu vào ($X$) dựa trên các trọng số hiện tại. Các bước được thực hiện tuần tự từ lớp này sang lớp khác.

\textbf{Ký hiệu:}
\begin{itemize}
    \item $a^{(l)}$: Đầu ra (activation) của lớp $l$.
    \item $z^{(l)}$: Tổng trọng số đầu vào (weighted sum) của lớp $l$ trước khi áp dụng hàm kích hoạt, $z^{(l)} = a^{(l-1)} \cdot (\theta^{(l-1)})^T$.
    \item $\theta^{(l)}$: Ma trận trọng số kết nối lớp $l$ và lớp $l+1$.
\end{itemize}

\textbf{Các bước tính toán:}
\begin{enumerate}
    \item \textbf{Bước 1:} Thêm cột bias vào ma trận đầu vào $X$ (giá trị 1).
    \begin{equation}
        a_1 = [\ \mathbf{1}\ ,\ X\ ] \quad \text{(Kích thước: } m \times 401\text{)}
        \label{eq:a1}
    \end{equation}
    Trong đó $\mathbf{1}$ là vector cột chứa $m$ phần tử 1.
    
    \item \textbf{Bước 2:} Tính toán cho lớp ẩn ($L_2$).
    \begin{align}
        z_2 &= a_1 \cdot \theta_1^T \quad \text{(Kích thước: } m \times 25\text{)} \label{eq:z2}\\
        a_2 &= \sigma(z_2) \quad \text{(Áp dụng hàm sigmoid từng phần tử)} \label{eq:a2_no_bias}\\
        a_2 &= [\ \mathbf{1}\ ,\ a_2\ ] \quad \text{(Thêm bias, kích thước: } m \times 26\text{)} \label{eq:a2_with_bias}
    \end{align}
    
    \item \textbf{Bước 3:} Tính toán cho lớp đầu ra ($L_3$).
    \begin{align}
        z_3 &= a_2 \cdot \theta_2^T \quad \text{(Kích thước: } m \times 10\text{)} \label{eq:z3}\\
        h &= a_3 = \sigma(z_3) \quad \text{(Kích thước: } m \times 10\text{)} \label{eq:h}
    \end{align}
    Kết quả $h$ là ma trận dự đoán, mỗi hàng $h^{(i)}$ là phân phối xác suất dự đoán cho mẫu thứ $i$.
\end{enumerate}

\subsection{Hàm mất mát (Loss Function) và Regularization}

Hàm mất mát đo lường sự khác biệt giữa dự đoán của mô hình ($h$) và nhãn thực tế ($y$). Chúng tôi sử dụng hàm \textbf{Cross-Entropy} kết hợp với điều chuẩn L2 (L2 Regularization hay Weight Decay).

\begin{equation}
    J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \sum_{k=1}^{K} \left[ y_k^{(i)} \log\left(h_k^{(i)}\right) + (1 - y_k^{(i)}) \log\left(1 - h_k^{(i)}\right) \right] + \frac{\lambda}{2m} \left( \sum_{j} \theta_{1,j}^2 + \sum_{j} \theta_{2,j}^2 \right)
    \label{eq:loss}
\end{equation}

\textbf{Giải thích:}
\begin{itemize}
    \item \textbf{Phần Cross-Entropy:} Hình phạt logarit cho các dự đoán sai. Nếu nhãn thực $y_k^{(i)}=1$ nhưng $h_k^{(i)}\approx0$, giá trị $-\log(h_k^{(i)})$ sẽ rất lớn. Tương tự, nếu $y_k^{(i)}=0$ nhưng $h_k^{(i)}\approx1$, $-\log(1-h_k^{(i)})$ cũng rất lớn.
    \item \textbf{Phần L2 Regularization ($\frac{\lambda}{2m} \sum \theta^2$):} Cộng thêm bình phương độ lớn của các trọng số (thường không bao gồm bias) vào hàm mất mát. Điều này "phạt" các mô hình có trọng số quá lớn, giúp chống overfitting bằng cách khuyến khích mô hình đơn giản hơn. Tham số $\lambda$ (lambda) kiểm soát mức độ điều chuẩn.
    \item $m$: Số mẫu trong batch/mini-batch.
    \item $K$: Số lớp (10).
\end{itemize}

\subsection{Quá trình Lan truyền ngược (Backpropagation) và Gradient Descent}

Đây là thuật toán cốt lõi để huấn luyện mạng nơ-ron. Nó tính toán đạo hàm (gradient) của hàm mất mát $J(\theta)$ đối với từng trọng số $\theta$ bằng quy tắc chuỗi (chain rule), sau đó cập nhật các trọng số theo hướng giảm gradient.

\subsubsection{Tính gradient (Backpropagation)}
Chúng ta bắt đầu từ sai số ở đầu ra và lan truyền ngược về các lớp trước.

\textbf{Ký hiệu:}
\begin{itemize}
    \item $\delta^{(l)}$: Sai số (error term) của lớp $l$, được định nghĩa là đạo hàm riêng của hàm mất mát đối với đầu vào $z^{(l)}$ của lớp đó: $\delta^{(l)} = \frac{\partial J}{\partial z^{(l)}}$.
\end{itemize}

\textbf{Các bước tính toán:}
\begin{enumerate}
    \item \textbf{Bước 1:} Tính sai số cho lớp đầu ra ($L_3$). Với hàm mất mát Cross-Entropy và hàm kích hoạt Sigmoid, công thức rút gọn rất đẹp:
    \begin{equation}
        \delta_3 = \frac{\partial J}{\partial z_3} = h - y \quad \text{(Kích thước: } m \times 10\text{)}
        \label{eq:delta3}
    \end{equation}
    Trong đó $y$ ở đây là ma trận one-hot encoding của nhãn thực.
    
    \item \textbf{Bước 2:} Tính sai số cho lớp ẩn ($L_2$). Sai số được lan truyền ngược qua trọng số $\theta_2$:
    \begin{equation}
        \delta_2 = (\delta_3 \cdot \theta_2[:, 1:]) \ \odot\ \sigma'(z_2) \quad \text{(Kích thước: } m \times 25\text{)}
        \label{eq:delta2}
    \end{equation}
    \begin{itemize}
        \item $\theta_2[:, 1:]$: Là ma trận $\theta_2$ bỏ đi cột đầu tiên (cột tương ứng với bias). Bias chỉ ảnh hưởng đến đầu ra chứ không lan truyền sai số ngược về lớp trước.
        \item $\odot$: Phép nhân phần tử (element-wise multiplication).
        \item $\sigma'(z_2)$: Đạo hàm của hàm sigmoid tại $z_2$, tính theo công thức \eqref{eq:sigmoid_derivative}.
    \end{itemize}
    
    \item \textbf{Bước 3:} Tính gradient của hàm mất mát đối với các trọng số. Gradient bao gồm đạo hàm của phần Cross-Entropy và phần regularization.
    \begin{align}
        \nabla_{\theta_2} J &= \frac{1}{m} \left( \delta_3^T \cdot a_2 \right) + \frac{\lambda}{m} \cdot \theta_2 \quad \text{(Kích thước: } 10 \times 26\text{)} \label{eq:grad_theta2}\\
        \nabla_{\theta_1} J &= \frac{1}{m} \left( \delta_2^T \cdot a_1 \right) + \frac{\lambda}{m} \cdot \theta_1 \quad \text{(Kích thước: } 25 \times 401\text{)} \label{eq:grad_theta1}
    \end{align}
    \textit{Lưu ý:} Thành phần regularization $\frac{\lambda}{m} \cdot \theta$ KHÔNG được áp dụng cho cột bias của $\theta_1$ và $\theta_2$ trong thực tế lập trình. Điều này đảm bảo bias không bị "phạt".
\end{enumerate}

\subsubsection{Cập nhật tham số (Gradient Descent)}
Sau khi có gradient, các trọng số được cập nhật theo hướng ngược lại với gradient để giảm hàm mất mát:
\begin{equation}
    \theta := \theta - \alpha \cdot \nabla_{\theta} J
    \label{eq:gradient_descent}
\end{equation}
Trong đó $\alpha$ (alpha) là tốc độ học (learning rate), một siêu tham số quan trọng quyết định kích thước bước cập nhật.

%==============================================================================
\section{Thiết kế song song và phân tán với MPI}
%==============================================================================

\subsection{Phân tích điểm cần song song hóa}

Trong thuật toán huấn luyện mạng nơ-ron theo batch (sử dụng toàn bộ tập dữ liệu), phần lớn thời gian tính toán nằm ở hai công đoạn:
\begin{enumerate}
    \item \textbf{Forward Propagation} (Eq. \ref{eq:z2}, \ref{eq:a2_no_bias}, \ref{eq:z3}, \ref{eq:h}): Các phép nhân ma trận và áp dụng hàm kích hoạt cho $m$ mẫu.
    \item \textbf{Backpropagation} (Eq. \ref{eq:delta3}, \ref{eq:delta2}, \ref{eq:grad_theta2}, \ref{eq:grad_theta1}): Tính toán gradient, cũng liên quan đến các phép nhân ma trận trên toàn bộ dữ liệu.
\end{enumerate}

Các phép tính này có một đặc điểm quan trọng: chúng có thể được thực hiện độc lập trên từng mẫu dữ liệu (hoặc từng nhóm mẫu), sau đó kết quả được tổng hợp lại. Tính chất này gọi là \textbf{tính song song theo dữ liệu (Data Parallelism)}.

\subsection{Chiến lược Song song hóa theo dữ liệu (Data Parallelism)}

Chiến lược của chúng tôi là phân chia tập dữ liệu huấn luyện ($m$ mẫu) thành $P$ phần nhỏ (chunks) gần bằng nhau, với $P$ là số tiến trình MPI. Mỗi tiến trình $p$ sẽ:
\begin{enumerate}
    \item Nhận một phần dữ liệu $D_p$ (khoảng $m/P$ mẫu).
    \item Giữ một bản sao đầy đủ của mô hình (các ma trận $\theta_1$ và $\theta_2$).
    \item Trong mỗi vòng lặp huấn luyện (epoch):
    \begin{itemize}
        \item Thực hiện \textbf{Forward Pass} và \textbf{Backward Pass} độc lập trên phần dữ liệu $D_p$ của mình, tính ra gradient cục bộ $\nabla_{\theta}^{(p)}$.
        \item Tham gia vào một thao tác \textbf{đồng bộ hóa toàn cục} (global synchronization) để tính gradient trung bình từ tất cả các tiến trình: $\overline{\nabla_{\theta}} = \frac{1}{P} \sum_{p=1}^{P} \nabla_{\theta}^{(p)}$.
        \item Cập nhật bản sao mô hình của mình sử dụng gradient trung bình chung này: $\theta := \theta - \alpha \cdot \overline{\nabla_{\theta}}$.
    \end{itemize}
\end{enumerate}

Sau bước đồng bộ, tất cả các tiến trình đều có cùng một bộ trọng số $\theta$ mới, đảm bảo tính nhất quán của mô hình. Phương pháp này còn được gọi là \textbf{Parallel Gradient Descent} hoặc \textbf{Synchronous Stochastic Gradient Descent} khi mỗi phần $D_p$ được coi như một mini-batch rất lớn.

\subsection{Thiết kế luồng xử lý với MPI}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{insert_image/parrallel_diagram.png}
    \caption{Sơ đồ chi tiết luồng xử lý song song với MPI trong một vòng lặp huấn luyện.}
    \label{fig:mpi-flow}
\end{figure}

\textbf{Mô tả luồng xử lý (Hình \ref{fig:mpi-flow}):}
\begin{enumerate}
    \item \textbf{Khởi tạo (Initialization):} Tiến trình gốc (Rank 0) đọc toàn bộ dữ liệu huấn luyện từ file.
    \item \textbf{Phân phối dữ liệu (Data Scattering):} Sử dụng \texttt{MPI\_Scatterv}, dữ liệu và nhãn được chia đều (hoặc gần đều) và gửi đến tất cả các tiến trình. \texttt{Scatterv} cho phép chia dữ liệu khi số mẫu không chia hết cho số tiến trình.
    \item \textbf{Broadcast trọng số (Weight Broadcasting):} Trọng số khởi tạo từ Rank 0 được broadcast tới tất cả tiến trình bằng \texttt{MPI\_Bcast} để đảm bảo mọi người bắt đầu với cùng một mô hình.
    \item \textbf{Vòng lặp huấn luyện (Training Loop):}
    \begin{itemize}
        \item \textbf{Tính toán cục bộ (Local Computation):} Mỗi tiến trình thực hiện forward/backward pass trên phần dữ liệu của mình, tính ra gradient cục bộ $\nabla_{\theta}^{(p)}$ và giá trị hàm mất mát cục bộ $J^{(p)}$.
        \item \textbf{Đồng bộ Gradient (Gradient Synchronization):} Sử dụng \texttt{MPI\_Allreduce} với phép tổng (\texttt{MPI\_SUM}) để tổng hợp gradient từ tất cả tiến trình. Kết quả tổng sau đó được chia cho $P$ (số tiến trình) để lấy trung bình. \texttt{Allreduce} đảm bảo mọi tiến trình đều nhận được kết quả gradient trung bình $\overline{\nabla_{\theta}}$ giống nhau.
        \item \textbf{Đồng bộ Loss (Loss Synchronization):} Tương tự, \texttt{MPI\_Allreduce} được dùng để tính tổng giá trị loss từ các tiến trình, sau đó chia cho $P$ để lấy loss trung bình cho toàn bộ dữ liệu. Chỉ Rank 0 in ra giá trị này để theo dõi.
        \item \textbf{Cập nhật trọng số (Weight Update):} Mỗi tiến trình tự cập nhật bản sao mô hình của mình sử dụng $\overline{\nabla_{\theta}}$ chung.
    \end{itemize}
    \item \textbf{Thu thập kết quả (Gathering Results):} Sau khi huấn luyện xong, để đánh giá độ chính xác, mỗi tiến trình có thể tính accuracy trên phần test data của mình. Sau đó, số lượng dự đoán đúng từ các tiến trình được tổng hợp về Rank 0 bằng \texttt{MPI\_Reduce} để tính accuracy cuối cùng.
\end{enumerate}

\subsection{Phân tích chi phí và lợi ích}

\subsubsection{Lợi ích (Speedup tiềm năng)}
\begin{itemize}
    \item \textbf{Giảm thời gian tính toán:} Thời gian cho forward/backward pass tỉ lệ với số mẫu. Nếu chia đều cho $P$ tiến trình, thời gian này lý tưởng sẽ giảm đi $P$ lần.
    \item \textbf{Xử lý bộ nhớ lớn:} Mỗi tiến trình chỉ cần lưu trữ $1/P$ lượng dữ liệu huấn luyện, cho phép xử lý tập dữ liệu lớn hơn tổng bộ nhớ của một máy đơn lẻ.
\end{itemize}

\subsubsection{Chi phí (Overhead)}
\begin{itemize}
    \item \textbf{Chi phí giao tiếp (Communication Overhead):} Các thao tác \texttt{Scatterv}, \texttt{Bcast}, \texttt{Allreduce} tốn thời gian. Chi phí này tăng lên khi số tiến trình $P$ tăng.
    \item \textbf{Thời gian chờ đồng bộ (Synchronization Delay):} Tất cả các tiến trình phải hoàn thành phần tính toán cục bộ của mình trước khi bước vào \texttt{Allreduce}. Tiến trình chậm nhất (straggler) sẽ làm chậm toàn bộ hệ thống.
    \item \textbf{Dư thừa tính toán (Computation Redundancy):} Mỗi tiến trình đều phải lưu trữ và cập nhật một bản sao đầy đủ của mô hình, dẫn đến dư thừa bộ nhớ.
\end{itemize}

\textbf{Định luật Amdahl} áp dụng ở đây: Tốc độ tăng tối đa bị giới hạn bởi phần tuần tự của chương trình (khởi tạo, đọc file, I/O) và chi phí đồng bộ hóa. Do đó, speedup thực tế thường nhỏ hơn $P$ lần.

\subsection{Công cụ và Cấu hình thực nghiệm}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|p{9cm}|}
\hline
\textbf{Hạng mục} & \textbf{Chi tiết} & \textbf{Ghi chú / Mục đích} \\
\hline
Ngôn ngữ C++ & C++17 & Biên dịch với \texttt{clang++ -O3 -std=c++17} (LLVM backend). \\
\hline
Ngôn ngữ Python & Python 3.x + numba & Sử dụng \texttt{numba @njit} để JIT compile thành machine code (cũng LLVM backend). \\
\hline
Thư viện song song & OpenMPI + mpi4py & C++ dùng MPI native API. Python dùng mpi4py wrapper. \\
\hline
Phần cứng & Apple Silicon Mac Mini & 10 nhân vật lý / 10 luồng, không có Hyper-Threading. \\
\hline
Dữ liệu & MNIST subset & 4000 train / 1000 test. C++ đọc CSV, Python đọc .mat. \\
\hline
Số tiến trình (P) & 1, 2, 4, 8 & Chạy trên một máy đa nhân, mỗi tiến trình gán với một CPU core. \\
\hline
\end{tabular}
\caption{Công cụ và cấu hình hệ thống}
\label{tab:tools}
\end{table}

\textbf{Các hàm MPI chính được sử dụng:}

\begin{table}[H]
\centering
\begin{tabular}{|l|p{11cm}|}
\hline
\textbf{Hàm MPI} & \textbf{Mục đích và vai trò trong thiết kế} \\
\hline
\texttt{MPI\_Init / MPI\_Finalize} & Bắt đầu và kết thúc môi trường MPI. Mọi tiến trình đều phải gọi. \\
\hline
\texttt{MPI\_Comm\_rank / MPI\_Comm\_size} & Nhận "địa chỉ" (rank) của tiến trình hiện tại và tổng số tiến trình (size). Dùng để xác định phần việc của mỗi tiến trình. \\
\hline
\texttt{MPI\_Bcast} & Rank 0 phát dữ liệu (vd: trọng số khởi tạo, tham số cấu hình) đến tất cả các tiến trình khác. Đảm bảo tính nhất quán ban đầu. \\
\hline
\texttt{MPI\_Scatterv} & Chia một mảng lớn trên Rank 0 thành các phần nhỏ và gửi đến từng tiến trình. Dùng để phân phối dữ liệu huấn luyện. "v" trong Scatterv cho phép chia kích thước phần dữ liệu không đồng đều. \\
\hline
\texttt{MPI\_Allreduce} & \textbf{Hàm quan trọng nhất.} Thực hiện phép toán tổng (SUM) trên các biến cục bộ (gradient, loss) của tất cả tiến trình và phân phối kết quả tổng về cho mọi tiến trình. Tạo ra gradient trung bình toàn cục. \\
\hline
\texttt{MPI\_Reduce} & Tương tự Allreduce, nhưng chỉ gửi kết quả tổng hợp về một tiến trình chỉ định (thường là Rank 0). Dùng để thu thập kết quả accuracy cuối cùng. \\
\hline
\texttt{MPI\_Barrier} & Đồng bộ hóa tất cả tiến trình tại một điểm, đảm bảo không tiến trình nào chạy vượt quá điểm này trước khi mọi tiến trình khác đến. \\
\hline
\end{tabular}
\caption{Các hàm MPI trọng tâm và chức năng}
\label{tab:mpi_funcs}
\end{table}

\subsection{Cấu trúc mã nguồn và Quy trình biên dịch}

Mã nguồn được tổ chức thành hai project riêng biệt cho hai ngôn ngữ:

\textbf{Phiên bản C++:}
\begin{verbatim}
project_cpp/
├── src/
│   ├── matrix_utils.h             # Thư viện ma trận: matmul, sigmoid, addBias
│   ├── sequential.cpp             # Phiên bản tuần tự
│   ├── parallel.cpp               # Phiên bản song song MPI
│   └── parallel_optimized.cpp     # Song song hóa cả evaluation
├── data/
│   ├── mnist_train.csv
│   └── mnist_test.csv
├── build/                         # File binary sau khi biên dịch
├── Makefile                       # Tự động hóa biên dịch
└── README.md
\end{verbatim}

\textbf{Phiên bản Python:}
\begin{verbatim}
project/
├── Mnist_sequential.py            # Tuần tự (numba @njit naive matmul)
├── Mnist_parallel.py              # Song song MPI (numba + mpi4py)
├── data/
│   └── mnistdata.mat              # Dữ liệu MNIST gốc
└── README.md
\end{verbatim}

\textbf{Quy trình biên dịch và chạy:}
\begin{verbatim}
# C++: Biên dịch và chạy
make parallel && mpirun -np 4 ./build/parallel

# Python: Chạy trực tiếp
mpirun -np 4 python Mnist_parallel.py
\end{verbatim}

%==============================================================================
\section{Kết quả thực nghiệm và Đánh giá}
%==============================================================================

\subsection{Thiết lập thực nghiệm}

Tất cả các thí nghiệm được chạy trên cùng một hệ thống phần cứng để đảm bảo tính công bằng khi so sánh.

\textbf{Phần cứng:}
\begin{itemize}
    \item CPU: Apple Silicon Mac Mini, 10 nhân vật lý / 10 luồng (không có Hyper-Threading)
    \item Bộ nhớ: Unified Memory Architecture
\end{itemize}

\textbf{Tham số huấn luyện (cố định cho cả hai ngôn ngữ):}
\begin{itemize}
    \item Số vòng lặp (iterations): 300
    \item Tốc độ học (learning rate - $\alpha$): 1.5
    \item Hệ số điều chuẩn ($\lambda$): 0.01
    \item Cấu trúc mạng: 400-25-10
    \item Hàm kích hoạt: Sigmoid cho cả lớp ẩn và đầu ra
    \item Random seed: 42 (trong mỗi ngôn ngữ)
\end{itemize}

\textbf{Phương pháp so sánh công bằng:} Để đảm bảo so sánh công bằng giữa C++ và Python, cả hai phiên bản đều sử dụng \textbf{cùng thuật toán}: phép nhân ma trận naive triple-loop (3 vòng lặp lồng nhau), hàm sigmoid element-wise, và các phép toán ma trận cơ bản. C++ được biên dịch bằng \texttt{clang++ -O3} (LLVM backend), Python sử dụng \texttt{numba @njit} (cũng LLVM backend) để JIT compile các hàm tính toán thành mã máy. Thời gian đo bao gồm cả thời gian JIT compilation của Python.

\subsection{Kết quả Scaling: C++ với MPI}

Bảng \ref{tab:cpp_scaling} trình bày kết quả chạy phiên bản C++ với số tiến trình MPI tăng dần từ 1 (tuần tự) đến 8.

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Phiên bản} & \textbf{Procs} & \textbf{Samples/Proc} & \textbf{Train Acc} & \textbf{Test Acc} & \textbf{Thời gian (s)} & \textbf{Speedup} \\
\hline
Sequential & 1 & 4000 & 93.60\% & 91.30\% & 19.58 & 1.00x \\
\hline
Parallel & 2 & 2000 & 93.60\% & 91.30\% & 10.74 & 1.82x \\
\hline
\textbf{Parallel} & \textbf{4} & \textbf{1000} & \textbf{93.60\%} & \textbf{91.30\%} & \textbf{5.99} & \textbf{3.27x} \\
\hline
Parallel & 8 & 500 & 93.60\% & 91.30\% & 5.18 & 3.78x \\
\hline
\end{tabular}
\caption{Kết quả scaling phiên bản C++ (clang++ -O3, naive matmul).}
\label{tab:cpp_scaling}
\end{table}

\subsection{Kết quả Scaling: Python với MPI}

Bảng \ref{tab:python_scaling} trình bày kết quả tương ứng cho phiên bản Python (sử dụng numba @njit, thời gian bao gồm cả JIT compilation).

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Phiên bản} & \textbf{Procs} & \textbf{Samples/Proc} & \textbf{Train Acc} & \textbf{Test Acc} & \textbf{Thời gian (s)} & \textbf{Speedup} \\
\hline
Sequential & 1 & 4000 & 94.05\% & 91.90\% & 15.67 & 1.00x \\
\hline
Parallel & 2 & 2000 & 94.05\% & 91.90\% & 9.08 & 1.73x \\
\hline
\textbf{Parallel} & \textbf{4} & \textbf{1000} & \textbf{94.05\%} & \textbf{91.90\%} & \textbf{5.73} & \textbf{2.74x} \\
\hline
Parallel & 8 & 500 & 94.05\% & 91.90\% & 6.61 & 2.37x \\
\hline
\end{tabular}
\caption{Kết quả scaling phiên bản Python (numba @njit, naive matmul, bao gồm JIT time).}
\label{tab:python_scaling}
\end{table}

\subsection{So sánh hiệu năng tổng hợp: C++ vs Python}

Bảng \ref{tab:cross_lang} đặt kết quả của cả hai ngôn ngữ cạnh nhau để so sánh trực tiếp hiệu quả song song hóa ở cùng số tiến trình.

\begin{table}[H]
\centering
\begin{tabular}{|c|l|c|c|c|c|c|}
\hline
\textbf{Procs} & \textbf{Ngôn ngữ} & \textbf{Train Acc} & \textbf{Test Acc} & \textbf{Thời gian (s)} & \textbf{Speedup} & \textbf{Efficiency} \\
\hline
\multirow{2}{*}{1 (seq)} & C++ & 93.60\% & 91.30\% & 19.58 & 1.00x & --- \\
                          & Python & 94.05\% & 91.90\% & 15.67 & 1.00x & --- \\
\hline
\multirow{2}{*}{2} & C++ & 93.60\% & 91.30\% & 10.74 & 1.82x & 91\% \\
                    & Python & 94.05\% & 91.90\% & 9.08 & 1.73x & 86\% \\
\hline
\multirow{2}{*}{4} & C++ & 93.60\% & 91.30\% & 5.99 & 3.27x & 82\% \\
                    & Python & 94.05\% & 91.90\% & 5.73 & 2.74x & 68\% \\
\hline
\multirow{2}{*}{8} & C++ & 93.60\% & 91.30\% & 5.18 & 3.78x & 47\% \\
                    & Python & 94.05\% & 91.90\% & 6.61 & 2.37x & 30\% \\
\hline
\end{tabular}
\caption{So sánh hiệu năng cross-language. Cả hai dùng cùng naive matmul, cùng LLVM compiler backend. Efficiency $= \text{Speedup} / P \times 100\%$.}
\label{tab:cross_lang}
\end{table}

\subsection{Phân tích chi tiết kết quả}

\subsubsection{Về Độ chính xác (Accuracy)}
\begin{itemize}
    \item \textbf{Tính nhất quán trong cùng ngôn ngữ:} Trong mỗi ngôn ngữ, tất cả các phiên bản (tuần tự và song song với 2, 4, 8 tiến trình) đều cho cùng một kết quả accuracy. Điều này khẳng định tính \textbf{đúng đắn} của thuật toán Data Parallelism: quá trình đồng bộ gradient bằng \texttt{MPI\_Allreduce} đảm bảo rằng kết quả tối ưu hóa tương đương với phiên bản tuần tự.
    \item \textbf{Chênh lệch giữa hai ngôn ngữ ($\sim$0.6\%):} Python đạt 91.90\% test accuracy so với 91.30\% của C++. Sự khác biệt nhỏ này là do:
    \begin{enumerate}
        \item \textbf{Bộ sinh số ngẫu nhiên khác nhau:} \texttt{numpy.random.randn} (Python) vs \texttt{std::mt19937 + normal\_distribution} (C++) tạo ra bộ trọng số khởi tạo khác nhau dù cùng seed, dẫn đến đường hội tụ (convergence path) khác nhau.
        \item \textbf{Cách nạp dữ liệu khác nhau:} Python đọc từ file \texttt{.mat} (định dạng gốc), C++ đọc từ file CSV (đã convert), có thể có sai khác nhỏ về thứ tự hoặc precision khi chuyển đổi.
        \item \textbf{Sai số tích lũy dấu phẩy động:} Qua 300 vòng lặp với hàng nghìn phép nhân ma trận, sự khác biệt cực nhỏ trong cách xử lý floating-point giữa hai compiler tích lũy lại.
    \end{enumerate}
    Tuy nhiên, cả hai đều đạt trên 91\% test accuracy, chứng tỏ cài đặt thuật toán là chính xác ở cả hai ngôn ngữ.
\end{itemize}

\subsubsection{Về Hiệu năng Song song trong C++}
\begin{itemize}
    \item \textbf{Scaling tốt ở 2-4 procs:} C++ đạt speedup 1.82x (2 procs) và 3.27x (4 procs), tương ứng với parallel efficiency 91\% và 82\%. Đây là kết quả rất tốt, cho thấy phần lớn thời gian tính toán đã được song song hóa hiệu quả.
    \item \textbf{Diminishing returns ở 8 procs:} Speedup chỉ tăng từ 3.27x (4 procs) lên 3.78x (8 procs), efficiency giảm mạnh xuống 47\%. Nguyên nhân:
    \begin{enumerate}
        \item \textbf{Dataset quá nhỏ:} Với 8 procs, mỗi process chỉ xử lý 500 mẫu --- thời gian tính toán mỗi iteration giảm xuống gần bằng chi phí giao tiếp \texttt{MPI\_Allreduce}.
        \item \textbf{Chi phí Allreduce tăng:} $\log_2(8) = 3$ bước reduce so với $\log_2(4) = 2$ bước.
        \item \textbf{Cache contention:} 8 processes chạy trên 10 cores chia sẻ L2/L3 cache, gây tranh chấp bộ nhớ đệm.
    \end{enumerate}
\end{itemize}

\subsubsection{Về Hiệu năng Song song trong Python}
\begin{itemize}
    \item \textbf{Scaling kém hơn C++:} Python đạt efficiency 86\% (2 procs) và 68\% (4 procs), thấp hơn C++ (91\% và 82\%). Ở 8 procs, Python thực sự \textbf{chậm lại} (6.61s vs 5.73s ở 4 procs, efficiency chỉ 30\%).
    \item \textbf{Nguyên nhân MPI overhead lớn hơn trong Python:}
    \begin{enumerate}
        \item \textbf{Serialization overhead:} mpi4py phải dùng pickle hoặc buffer protocol để serialize numpy arrays trước khi gửi qua MPI, trong khi C++ gửi trực tiếp raw memory.
        \item \textbf{Python interpreter overhead:} Phần code ngoài \texttt{@njit} (MPI calls, array slicing, hstack) vẫn chạy qua Python interpreter, tạo thêm latency mỗi iteration.
        \item \textbf{GIL (Global Interpreter Lock):} Mặc dù MPI chạy multi-process (tránh GIL), nhưng phần khởi tạo và kết thúc mỗi iteration vẫn bị GIL ảnh hưởng.
    \end{enumerate}
\end{itemize}

\subsubsection{So sánh Cross-Language: C++ vs Python}
\begin{itemize}
    \item \textbf{Sequential gần tương đương:} Python sequential (15.67s) nhanh hơn C++ (19.58s) một chút. Điều này có vẻ bất ngờ, nhưng giải thích bằng cả hai đều dùng cùng LLVM compiler backend: \texttt{clang++ -O3} cho C++ và \texttt{numba @njit} cho Python. Numba tối ưu hóa memory layout contiguous arrays tốt hơn so với \texttt{std::vector<std::vector<double>>} (non-contiguous) trong C++. Tuy nhiên, thời gian Python đã bao gồm cả JIT compilation overhead.
    \item \textbf{C++ scale tốt hơn khi tăng procs:} Ở 4 procs, C++ đã rút ngắn khoảng cách (5.99s vs 5.73s). Ở 8 procs, \textbf{C++ vượt qua Python} rõ ràng (5.18s vs 6.61s). Điều này phản ánh MPI overhead thấp hơn đáng kể trong C++ so với Python.
    \item \textbf{Sweet spot = 4 procs:} Cả hai ngôn ngữ đều đạt hiệu quả tốt nhất ở 4 tiến trình với dataset 4000 mẫu. Vượt qua 4 procs, chi phí giao tiếp bắt đầu lấn át lợi ích tính toán.
\end{itemize}

\subsection{Đánh giá Hiệu quả Song song (Parallel Efficiency)}

Hiệu suất song song được tính bằng: $E = \frac{S}{P} \times 100\%$, với $S$ là speedup thực tế, $P$ là số tiến trình.

\textbf{So sánh Parallel Efficiency giữa hai ngôn ngữ:}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Procs} & \textbf{Speedup C++} & \textbf{Efficiency C++} & \textbf{Speedup Python} & \textbf{Efficiency Python} \\
\hline
2 & 1.82x & 91\% & 1.73x & 86\% \\
\hline
4 & 3.27x & 82\% & 2.74x & 68\% \\
\hline
8 & 3.78x & 47\% & 2.37x & 30\% \\
\hline
\end{tabular}
\caption{So sánh Parallel Efficiency giữa C++ và Python.}
\label{tab:efficiency}
\end{table}

\textbf{Phân tích:}
\begin{itemize}
    \item C++ duy trì efficiency trên 80\% cho đến 4 procs, chứng tỏ thiết kế Data Parallelism với MPI rất hiệu quả khi chi phí giao tiếp (raw memory copy) thấp.
    \item Python mất efficiency nhanh hơn do MPI overhead cao hơn (serialization, interpreter). Ở 8 procs, efficiency chỉ 30\% --- phần lớn thời gian bị lãng phí vào giao tiếp và đồng bộ.
    \item \textbf{Áp dụng định luật Amdahl:} Từ kết quả C++ 4 procs ($S = 3.27$), ta ước tính tỷ lệ phần tuần tự: $f \approx 5.6\%$. Dự đoán cho 8 procs: $S_{\text{Amdahl}} = \frac{1}{0.056 + 0.944/8} \approx 5.75$. Thực tế C++ chỉ đạt 3.78x, thấp hơn nhiều do overhead communication tăng phi tuyến với dataset nhỏ.
\end{itemize}

\subsection{Thử nghiệm mở rộng: Song song hóa quá trình Đánh giá (Parallel Evaluation)}

Sau khi huấn luyện song song, quá trình đánh giá (evaluation/prediction) trên tập test (1000 mẫu) cũng có thể được song song hóa để giảm thời gian tổng thể. Chúng tôi thực hiện:
\begin{enumerate}
    \item Chia tập test cho 4 tiến trình bằng \texttt{MPI\_Scatterv}.
    \item Mỗi tiến trình dùng mô hình đã huấn luyện để dự đoán trên phần dữ liệu test của mình.
    \item Dùng \texttt{MPI\_Reduce} để cộng số lượng dự đoán đúng từ các tiến trình về Rank 0 và tính accuracy.
\end{enumerate}

\textbf{Kết quả:}
\begin{itemize}
    \item Thời gian đánh giá tuần tự: $\sim$0.02s.
    \item Thời gian đánh giá song song: $\sim$0.014s.
\end{itemize}
Với tập test quá nhỏ (1000 mẫu), chi phí giao tiếp cho việc scatter và reduce gần như bằng hoặc lớn hơn thời gian tính toán thực tế, dẫn đến cải thiện không đáng kể (0.006s). Điều này cho thấy, việc song song hóa chỉ có lợi khi khối lượng công việc tính toán đủ lớn để "che" được chi phí giao tiếp.

\subsection{Phân tích đường cong Hội tụ và Hàm mất mát}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{insert_image/loss_curve.png} % Giả sử có hình
    \caption{So sánh đường cong hàm mất mát (Loss) giữa phiên bản Tuần tự và Song song (C++). Hai đường gần như trùng khớp, chứng tỏ quá trình tối ưu hóa diễn ra tương đồng.}
    \label{fig:loss_curve}
\end{figure}

Quan sát log output (hoặc biểu đồ nếu có), hàm mất mát của cả hai phiên bản C++ (tuần tự và song song) đều giảm nhanh trong khoảng 50 vòng lặp đầu và sau đó giảm chậm dần, cho thấy mô hình đang hội tụ. Sự trùng khớp của hai đường cong này một lần nữa khẳng định tính đúng đắn của thuật toán song song.

\subsection{Tổng kết và Thảo luận}

\begin{enumerate}
    \item \textbf{Thành công chính:} Nghiên cứu đã triển khai thành công pipeline huấn luyện mạng nơ-ron phân tán sử dụng MPI trên \textbf{cả hai ngôn ngữ} C++ và Python, với cùng thuật toán naive matmul đảm bảo so sánh công bằng. C++ parallel 4 procs đạt thời gian tốt nhất 5.99 giây (speedup 3.27x), Python parallel 4 procs đạt 5.73 giây (speedup 2.74x).
    \item \textbf{Tính đúng đắn được đảm bảo:} Trong cả hai ngôn ngữ, tất cả phiên bản song song (2, 4, 8 procs) đều cho cùng accuracy với phiên bản tuần tự. Việc sử dụng \texttt{MPI\_Allreduce} để đồng bộ gradient trung bình đảm bảo tính tương đương toán học với Gradient Descent tuần tự.
    \item \textbf{C++ scaling vượt trội:} C++ đạt parallel efficiency 82\% (4 procs) so với Python 68\%. Ở 8 procs, C++ vẫn cải thiện (3.78x) trong khi Python bắt đầu chậm lại (2.37x). Lợi thế của C++ nằm ở MPI communication overhead thấp (raw memory copy vs pickle serialization).
    \item \textbf{Điểm hạn chế thực nghiệm:}
    \begin{itemize}
        \item \textbf{Quy mô dữ liệu nhỏ:} 4000 mẫu huấn luyện khiến communication overhead chiếm tỷ trọng lớn, đặc biệt ở 8 procs (chỉ 500 mẫu/proc). Với dataset lớn hơn, efficiency dự kiến sẽ cao hơn.
        \item \textbf{Chạy trên shared memory:} Tất cả tiến trình chạy chung bộ nhớ trên một máy. Overhead giao tiếp thấp hơn nhiều so với mạng cụm máy tính thực sự (multi-node cluster).
        \item \textbf{Naive matmul:} Cả hai ngôn ngữ đều dùng phép nhân ma trận thủ công (triple-loop) thay vì thư viện BLAS tối ưu, nhằm mục đích so sánh công bằng. Trong thực tế, C++ + BLAS hoặc Python + NumPy sẽ nhanh hơn rất nhiều.
    \end{itemize}
\end{enumerate}

%==============================================================================
\section{Kết luận và Hướng phát triển}
%==============================================================================

\subsection{Kết luận}

Báo cáo này đã trình bày một nghiên cứu thực nghiệm về việc áp dụng tính toán song song và phân tán, thông qua giao thức MPI, để tăng tốc độ huấn luyện mạng nơ-ron cho bài toán phân loại chữ số viết tay MNIST. Nghiên cứu được thực hiện trên cả hai ngôn ngữ C++ và Python với cùng thuật toán (naive matmul) để đảm bảo so sánh công bằng. Các kết quả chính được rút ra:

\begin{enumerate}
    \item \textbf{Về mặt thuật toán:} Chiến lược \textbf{Song song hóa theo dữ liệu (Data Parallelism)} kết hợp với đồng bộ gradient đồng bộ thông qua \texttt{MPI\_Allreduce} là phương pháp hiệu quả và \textbf{đảm bảo tính đúng đắn}. Tất cả phiên bản song song (2, 4, 8 procs) cho cùng accuracy với phiên bản tuần tự trong mỗi ngôn ngữ.
    \item \textbf{Về mặt hiệu năng:} C++ đạt parallel efficiency 82\% ở 4 procs (speedup 3.27x), Python đạt 68\% (speedup 2.74x). C++ thể hiện khả năng scaling vượt trội nhờ MPI communication overhead thấp. Ở 8 procs, C++ vẫn cải thiện (3.78x) trong khi Python bắt đầu giảm hiệu suất (2.37x).
    \item \textbf{Về so sánh cross-language:} Khi dùng cùng thuật toán và cùng LLVM compiler backend, C++ sequential (19.58s) và Python sequential (15.67s) cho thời gian tương đương. Sự khác biệt chính nằm ở khả năng scaling: C++ với MPI native cho phép giao tiếp hiệu quả hơn khi số tiến trình tăng.
    \item \textbf{Về mặt kỹ thuật:} Nghiên cứu cung cấp thiết kế chi tiết và triển khai cụ thể cho mô hình Data Parallelism với MPI trên hai ngôn ngữ, có thể dùng làm tài liệu tham khảo cho các bài toán tương tự.
\end{enumerate}

\subsection{Hạn chế của nghiên cứu hiện tại}

\begin{itemize}
    \item \textbf{Mô hình đơn giản:} Mạng nơ-ron 3 lớp với hàm sigmoid là kiến trúc rất cơ bản. Các mô hình hiện đại như CNN, Transformer phức tạp hơn nhiều về mặt tính toán và truyền thông.
    \item \textbf{Quy mô dữ liệu và hệ thống nhỏ:} Thử nghiệm trên tập dữ liệu con và trên một máy tính đa nhân, chưa phản ánh đầy đủ thách thức của môi trường phân tán quy mô lớn (nhiều node, mạng latency cao).
    \item \textbf{Chưa tối ưu hóa cao:} Các phép toán ma trận được triển khai thủ công, chưa sử dụng các thư viện tối ưu như BLAS (OpenBLAS, Intel MKL) hay frameworks chuyên sâu như CUDA cho GPU.
\end{itemize}

\subsection{Hướng phát triển trong tương lai}

Dựa trên những kết quả và hạn chế nêu trên, các hướng nghiên cứu và phát triển tiếp theo có thể bao gồm:

\begin{enumerate}
    \item \textbf{Mở rộng quy mô và độ phức tạp:}
    \begin{itemize}
        \item Thử nghiệm trên toàn bộ tập MNIST (60k mẫu) hoặc các bộ dữ liệu lớn hơn (CIFAR-10, ImageNet subset).
        \item Áp dụng cho các kiến trúc mạng phức tạp hơn như Mạng nơ-ron Tích chập (CNN) để xử lý ảnh hoặc RNN/LSTM cho dữ liệu chuỗi.
    \end{itemize}
    
    \item \textbf{Tối ưu hóa hiệu năng sâu:}
    \begin{itemize}
        \item Tích hợp các thư viện tính toán hiệu năng cao như \textbf{OpenBLAS} hoặc \textbf{Intel MKL} cho các phép toán đại số tuyến tính cơ bản, thay vì tự viết loops.
        \item Kết hợp \textbf{MPI với OpenMP} (mô hình hybrid): Dùng MPI để giao tiếp giữa các node/tầng lớn, và dùng OpenMP để tận dụng đa luồng trên từng node (multi-core). Đây là mô hình phổ biến trong siêu tính toán hiện đại.
        \item Chuyển sang tính toán trên \textbf{GPU} bằng \textbf{CUDA} hoặc \textbf{OpenCL}. Một chiến lược khả thi là dùng MPI để quản lý nhiều GPU (mỗi tiến trình MPI kiểm soát một GPU), và dùng thư viện như cuBLAS hoặc cuDNN bên trong mỗi tiến trình.
    \end{itemize}
    
    \item \textbf{Cải tiến thuật toán song song:}
    \begin{itemize}
        \item Thử nghiệm với \textbf{Asynchronous SGD}: Thay vì chờ đồng bộ sau mỗi vòng lặp, các worker có thể cập nhật tham số một cách không đồng bộ. Phương pháp này giảm thời gian chờ nhưng có thể ảnh hưởng đến độ hội tụ.
        \item Áp dụng \textbf{Gradient Compression}: Nén gradient trước khi gửi qua mạng (ví dụ: chỉ gửi các gradient lớn hoặc lượng tử hóa gradient) để giảm đáng kể lượng dữ liệu giao tiếp, đặc biệt quan trọng trong môi trường multi-node.
    \end{itemize}
    
    \item \textbf{Xây dựng framework tổng quát hơn:}
    \begin{itemize}
        \item Đóng gói code thành một thư viện nhỏ, tổng quát hóa cho phép người dùng dễ dàng định nghĩa cấu trúc mạng và các hàm kích hoạt.
        \item Hỗ trợ các thuật toán tối ưu hóa tiên tiến hơn như Adam, RMSprop thay vì chỉ Gradient Descent thuần túy.
    \end{itemize}
\end{enumerate}

\textbf{Lời kết:} Nghiên cứu này đã thành công trong việc minh họa nguyên lý và lợi ích cốt lõi của tính toán song song/phân tán trong học sâu. Bằng việc triển khai cùng thuật toán trên cả C++ và Python với MPI, chúng tôi không chỉ chứng minh tính hiệu quả của Data Parallelism mà còn cung cấp một so sánh cross-language có kiểm soát, cho thấy C++ scale tốt hơn Python khi số tiến trình tăng. Kết quả mở đường cho việc xử lý các bài toán học máy quy mô lớn hơn, phức tạp hơn trong tương lai.

%==============================================================================
\section*{Tài liệu tham khảo}
%==============================================================================
\addcontentsline{toc}{section}{Tài liệu tham khảo}

\begin{enumerate}
    \item LeCun, Y., Bottou, L., Bengio, Y., \& Haffner, P. (1998). Gradient-based learning applied to document recognition. \textit{Proceedings of the IEEE}, 86(11), 2278-2324. (Giới thiệu về MNIST và ứng dụng mạng nơ-ron).
    
    \item Glorot, X., \& Bengio, Y. (2010). Understanding the difficulty of training deep feedforward neural networks. \textit{In Proceedings of the thirteenth international conference on artificial intelligence and statistics} (pp. 249-256). (Phương pháp khởi tạo Xavier).
    
    \item Dean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Mao, M., ... \& Ng, A. Y. (2012). Large scale distributed deep networks. \textit{In Advances in neural information processing systems} (pp. 1223-1231). (Nền tảng về Distributed Deep Learning, giới thiệu DistBelief).
    
    \item MPI Forum. (2015). \textit{MPI: A Message-Passing Interface Standard, Version 3.1}. Truy cập từ \url{https://www.mpi-forum.org/docs/mpi-3.1/mpi31-report.pdf} (Tài liệu tiêu chuẩn chính thức về MPI).
    
    \item Li, M., Andersen, D. G., Park, J. W., Smola, A. J., Ahmed, A., Josifovski, V., ... \& Su, B. Y. (2014). Scaling distributed machine learning with the parameter server. \textit{In 11th USENIX Symposium on Operating Systems Design and Implementation (OSDI 14)} (pp. 583-598). (Kiến trúc Parameter Server cho machine learning phân tán).
    
    \item Goodfellow, I., Bengio, Y., \& Courville, A. (2016). \textit{Deep learning}. MIT press. (Sách giáo khoa toàn diện về Học sâu).
    
    \item Gropp, W., Lusk, E., \& Skjellum, A. (2014). \textit{Using MPI: portable parallel programming with the message-passing interface} (Vol. 1). MIT press. (Sách hướng dẫn sử dụng MPI kinh điển).
\end{enumerate}

\end{document}